{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics Importation \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# For Detailed Stats Output\n",
    "import statsmodels.api as sm\n",
    "# The linear regression models \n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LassoCV, ElasticNetCV\n",
    "# Instantiating the linear regression models\n",
    "ols = LinearRegression()\n",
    "ridge = Ridge()\n",
    "lasso  = Lasso()\n",
    "lassocv = LassoCV()\n",
    "elasticnet = ElasticNet()\n",
    "elasticnetcv = ElasticNetCV()\n",
    "# The tree model\n",
    "from sklearn import tree\n",
    "# Instantiating the tree model (regression type)\n",
    "regressor = tree.DecisionTreeRegressor()\n",
    "# The ensemble model for random forest and bagging\n",
    "from sklearn import ensemble\n",
    "# Instantiating the ensemble models\n",
    "randomForest = ensemble.RandomForestRegressor()\n",
    "bagging = ensemble.BaggingRegressor()\n",
    "# Instantiating the boost models\n",
    "gbm = ensemble.GradientBoostingRegressor()\n",
    "abr = ensemble.AdaBoostRegressor()\n",
    "# xg boost\n",
    "import xgboost as xgb\n",
    "# lg boost\n",
    "import lightgbm as lgb\n",
    "# K mean clustering\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans()\n",
    "# The model selection for cross validation, k fold splits, train_test_split, grid search etc. \n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Some automatic feature selection functions (recursive finding, best feature selection etc.)\n",
    "import sklearn.feature_selection as fs\n",
    "# Importing the different error evaluation/metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "# Importing PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# Making it so that we can see all columns of the dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Import data\n",
    "df=pd.read_csv('standardized_dummified_df_total_garage_car_clean.csv', index_col='Id')\n",
    "df_test=pd.read_csv('standardized_dummified_df_test_garage_car_clean.csv', index_col='Id')\n",
    "\n",
    "lencoded_df=pd.read_csv('standardized_label_encode_df_total_garage_car_clean.csv', index_col='Id')\n",
    "lencoded_df_test=pd.read_csv('standardized_label_encode_df_test_garage_car_clean.csv', index_col='Id')\n",
    "\n",
    "x=df[~df.SalePrice.isnull()].drop(['SalePrice'],axis=1)\n",
    "y=df[~df.SalePrice.isnull()].SalePrice\n",
    "\n",
    "lencoded_x=lencoded_df[~lencoded_df.SalePrice.isnull()].drop(['SalePrice'],axis=1)\n",
    "lencoded_y=lencoded_df[~lencoded_df.SalePrice.isnull()].SalePrice\n",
    "\n",
    "kaggle_test=df_test\n",
    "lencoded_kaggle_test=lencoded_df_test\n",
    "# df_test must have (1459) rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undummify(dataframe):\n",
    "    tot_col=dataframe.columns\n",
    "    cat_col=list(tot_col[tot_col.str.contains('__')])\n",
    "    cat_col_split=set(map(lambda x:x.split('__')[0],cat_col))\n",
    "    cat_dict={}\n",
    "    for col in cat_col_split:\n",
    "        sub_df=dataframe[cat_col].loc[:,list(map(lambda x:col in x, dataframe[cat_col].columns))]\n",
    "        for i in sub_df.columns:\n",
    "            label_num=int(i.split('__')[1])\n",
    "            sub_df.loc[:,i]=np.array(sub_df.loc[:,i])*label_num\n",
    "        cat_dict[col]=sub_df.sum(axis=1)+1\n",
    "    df1=dataframe.drop(cat_col,axis=1)\n",
    "    df2=pd.DataFrame(cat_dict)\n",
    "    return pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def important_coefs_lasso(model, dataframe,returnlist):\n",
    "    '''\n",
    "    - A function that returns non-zero coefficients in order from a lasso model output\n",
    "    ---------------\n",
    "    - dataframe: dataframe of model inputs\n",
    "    - model: model object\n",
    "    '''\n",
    "    lassoCoef = pd.Series(model.coef_, index=dataframe.columns)\n",
    "    if returnlist=='Pos': \n",
    "        lassoCoef=lassoCoef[np.abs(lassoCoef)>0]\n",
    "        return lassoCoef.sort_values(ascending=False)\n",
    "    elif returnlist=='Zero':\n",
    "        lassoCoef=lassoCoef[np.abs(lassoCoef)<=1e-5]\n",
    "        return lassoCoef.sort_values(ascending=False)\n",
    "    else: \n",
    "        return lassoCoef.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_ridge_coefs(model, dataframe):\n",
    "    ridge_coef = pd.Series(model.coef_, index=dataframe.columns)\n",
    "    ridge_coef.sort_values(ascending=False)\n",
    "    order = abs(ridge_coef).sort_values(ascending=False)\n",
    "    return ridge_coef[order.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "lencoded_trainX, lencoded_testX, lencoded_trainY, lencoded_testY = train_test_split(lencoded_x, lencoded_y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.013889524337562848\n",
      "Test RMSE in $$: 21795.77167423124\n"
     ]
    }
   ],
   "source": [
    "# Initial Lasso\n",
    "# trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "alphaRange = np.linspace(10e-6,0.05,100)\n",
    "grid_param=[{'alpha': alphaRange}]\n",
    "para_search = GridSearchCV(estimator=Lasso(max_iter=5000),param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "para_search.fit(trainX, trainY)\n",
    "lasso_best_score = para_search.best_score_\n",
    "lasso_best_alpha = para_search.best_params_['alpha']\n",
    "lasso.set_params(alpha=lasso_best_alpha, normalize = False)\n",
    "lasso.fit(trainX,trainY)\n",
    "\n",
    "l_MSE = np.mean((lasso.predict(testX)-testY)**2)\n",
    "l_RMSE_in_dollars = np.mean((np.exp(lasso.predict(testX))-np.exp(testY))**2)**0.5\n",
    "print('Test MSE: %s' %(l_MSE))\n",
    "print('Test RMSE in $$: %s' %(l_RMSE_in_dollars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "########################################################\n",
    "######## Predict Kaggle ################################\n",
    "para_search.fit(x,y)\n",
    "one_lasso_predict_for_test=para_search.predict(x) # <----- for ensemble coefficient optimization\n",
    "one_lasso_predict=para_search.predict(kaggle_test)\n",
    "######## Predict Kaggle ################################\n",
    "########################################################\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove Worst Features for Lasso right away\n",
    "lasso_worst_feat=important_coefs_lasso(lasso, trainX,'Zero')\n",
    "lasso_df=trainX.copy()\n",
    "lasso_df_test=testX.copy()\n",
    "lasso_df.drop(lasso_worst_feat.index,axis=1,inplace=True)\n",
    "lasso_df_test.drop(lasso_worst_feat.index,axis=1,inplace=True)\n",
    "l_para_search=GridSearchCV(estimator=Lasso(max_iter=5000,tol=0.007),param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "l_para_search.fit(lasso_df,trainY)\n",
    "l_lasso_score=-l_para_search.score(lasso_df,trainY)\n",
    "l_lasso_test_score=-l_para_search.score(lasso_df_test,testY)\n",
    "l_RMSE_in_dollars=np.mean((np.exp(-l_para_search.predict(lasso_df_test))-np.exp(testY))**2)**0.5\n",
    "print('train MSE: %s' %(l_lasso_score))\n",
    "print('test MSE: %s' %(l_lasso_test_score))\n",
    "print('Test RMSE in $$: %s' %(l_RMSE_in_dollars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "########################################################\n",
    "######## Predict Kaggle ################################\n",
    "# Perform same feature change on kaggle test\n",
    "lasso_fit_df=x.drop(lasso_worst_feat.index,axis=1)\n",
    "l_para_search.fit(lasso_fit_df,y)\n",
    "lasso_kaggle_test=kaggle_test.drop(lasso_worst_feat.index,axis=1)\n",
    "two_lasso_predict_for_test=l_para_search.predict(lasso_fit_df) # <----- for ensemble coefficient optimization\n",
    "two_lasso_predict=l_para_search.predict(lasso_kaggle_test)\n",
    "######## Predict Kaggle ################################\n",
    "########################################################\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lasso_best_feat=important_coefs_lasso(lasso, trainX,'All')\n",
    "# lasso_best_feat=abs(lasso_best_feat)\n",
    "# lasso_best_feat=lasso_best_feat.sort_values(ascending=False)\n",
    "# lasso_best_feat=list(lasso_best_feat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Recursive Lasso\n",
    "# recursive_lasso_score=[]\n",
    "# recursive_lasso_test_score=[]\n",
    "# i=0\n",
    "# lasso_df=trainX.copy()\n",
    "# lasso_df_test=testX.copy()\n",
    "# for col in lasso_best_feat[-1:-101:-1]:\n",
    "#     i+=1\n",
    "#     lasso_df.drop(col,axis=1,inplace=True)\n",
    "#     lasso_df_test.drop(col,axis=1,inplace=True)\n",
    "#     recursive_para_search=GridSearchCV(estimator=Lasso(max_iter=5000,tol=0.007),param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "#     recursive_para_search.fit(lasso_df,trainY)\n",
    "#     recursive_lasso_score.append(recursive_para_search.score(lasso_df,trainY))\n",
    "#     recursive_lasso_test_score.append(recursive_para_search.score(lasso_df_test,testY))\n",
    "#     print(i,'/',np.array(lasso_best_feat[-1:-101:-1]).shape[0],end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(np.array(recursive_lasso_score)*-1,c='red', label='training error')\n",
    "# plt.plot(np.array(recursive_lasso_test_score)*-1,c='blue', label='test error')\n",
    "# plt.ylabel('MSE')\n",
    "# plt.xlabel('Features Taken Out')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_best_feat=important_coefs_lasso(lasso, trainX,'All')\n",
    "lasso_best_feat=abs(lasso_best_feat)\n",
    "lasso_best_feat=lasso_best_feat.sort_values(ascending=False)\n",
    "lasso_best_feat=list(lasso_best_feat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive linear regression\n",
    "ols_score=[]\n",
    "ols_test_score=[]\n",
    "i=0\n",
    "ols_df=trainX.copy()\n",
    "ols_df_test=testX.copy()\n",
    "for col in lasso_best_feat[-1:-201:-1]:\n",
    "    i+=1\n",
    "    ols_df.drop(col,axis=1,inplace=True)\n",
    "    ols_df_test.drop(col,axis=1,inplace=True)\n",
    "    ols.fit(ols_df,trainY)\n",
    "    ols_score.append(metrics.mean_squared_error(trainY, ols.predict(ols_df)))\n",
    "    ols_test_score.append(metrics.mean_squared_error(testY, ols.predict(ols_df_test)))\n",
    "    print(i,'/',np.array(lasso_best_feat[-1:-201:-1]).shape[0],end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylim([0,0.05])\n",
    "plt.plot(np.array(ols_score),c='red', label='training error')\n",
    "plt.plot(np.array(ols_test_score),c='blue', label='test error')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Features Taken Out')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "########################################################\n",
    "######## Predict Kaggle ################################\n",
    "# we see that mse begins rise up\n",
    "ols_df=pd.concat([trainX.copy(),testX.copy()],axis=0,sort=False)\n",
    "totalY=pd.concat([trainY,testY],axis=0,sort=False)\n",
    "\n",
    "ols.fit(ols_df[lasso_best_feat[0:-150]],totalY)\n",
    "ols_predict_for_test=ols.predict(ols_df[lasso_best_feat[0:-150]]) # <----- for ensemble coefficient optimization\n",
    "ols_predict=ols.predict(kaggle_test[lasso_best_feat[0:-150]])\n",
    "######## Predict Kaggle ################################\n",
    "########################################################\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initial Ridge\n",
    "trainX, testX, trainY, testY = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "r_alphaRange = np.linspace(10e-3,100,100)\n",
    "r_grid_param=[{'alpha': r_alphaRange}]\n",
    "r_para_search = GridSearchCV(estimator=Ridge(max_iter=5000),param_grid=r_grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "r_para_search.fit(trainX, trainY)\n",
    "\n",
    "ridge_best_score = r_para_search.best_score_\n",
    "ridge_best_alpha = r_para_search.best_params_['alpha']\n",
    "ridge.set_params(alpha=ridge_best_alpha, normalize = False)\n",
    "ridge.fit(trainX,trainY)\n",
    "\n",
    "r_MSE = np.mean((ridge.predict(testX)-testY)**2)\n",
    "r_RMSE_in_dollars = np.mean((np.exp(ridge.predict(testX))-np.exp(testY))**2)**0.5\n",
    "print('Test MSE: %s' %(r_MSE))\n",
    "print('Test RMSE in $$: %s' %(r_RMSE_in_dollars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge_best_feat=sort_ridge_coefs(ridge, trainX).index\n",
    "# Recursive ridge\n",
    "recursive_ridge_score=[]\n",
    "recursive_ridge_test_score=[]\n",
    "i=0\n",
    "ridge_df=trainX.copy()\n",
    "ridge_df_test=testX.copy()\n",
    "for col in ridge_best_feat[-1:-101:-1]:\n",
    "    i+=1\n",
    "    ridge_df.drop(col,axis=1,inplace=True)\n",
    "    ridge_df_test.drop(col,axis=1,inplace=True)\n",
    "    recursive_r_para_search=GridSearchCV(estimator=Ridge(max_iter=5000),param_grid=grid_param, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "    recursive_r_para_search.fit(ridge_df,trainY)\n",
    "    recursive_ridge_score.append(recursive_r_para_search.score(ridge_df,trainY))\n",
    "    recursive_ridge_test_score.append(recursive_r_para_search.score(ridge_df_test,testY))\n",
    "    print(i,'/',np.array(ridge_best_feat[-1:-101:-1]).shape[0],end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.array(recursive_ridge_score)*-1,c='red', label='training error')\n",
    "plt.plot(np.array(recursive_ridge_test_score)*-1,c='blue', label='test error')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Features Taken Out')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "########################################################\n",
    "######## Predict Kaggle ################################\n",
    "# we see that mse begins rise up\n",
    "ridge_df=pd.concat([trainX.copy(),testX.copy()],axis=0,sort=False)\n",
    "totalY=pd.concat([trainY,testY],axis=0,sort=False)\n",
    "\n",
    "recursive_r_para_search.fit(ridge_df[ridge_best_feat[0:-78]],totalY) \n",
    "ridge_predict_for_test=recursive_r_para_search.predict(ridge_df[ridge_best_feat[0:-78]]) # <----- for ensemble coefficient optimization\n",
    "ridge_predict=recursive_r_para_search.predict(kaggle_test[ridge_best_feat[0:-78]])\n",
    "######## Predict Kaggle ################################\n",
    "########################################################\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Forest\n",
    "param_grid = {\n",
    "    'max_depth' : range(5,20),\\\n",
    "    'max_features': range(5,20)\n",
    "}\n",
    "randomForest = ensemble.RandomForestRegressor()\n",
    "grid_search_forest = GridSearchCV(ensemble.RandomForestRegressor(n_estimators=100,criterion=\"mse\",\\\n",
    "                                                                 min_samples_leaf=2,min_samples_split=2,\\\n",
    "                                                                 bootstrap=True,oob_score = True,n_jobs=-1),\\\n",
    "                                  param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1,refit=True)\n",
    "%time grid_search_forest.fit(lencoded_trainX, lencoded_trainY)\n",
    "\n",
    "# Print results    \n",
    "print('MSE Score on test data set (using best parameters): {0:.3f}'.format(-grid_search_forest.score(lencoded_testX, lencoded_testY)))\n",
    "print('RMSE in $$ on test data set (using best parameters): {0:.1f}'.format(\\\n",
    "      np.mean((np.exp(grid_search_forest.predict(lencoded_testX))-np.exp(lencoded_testY))**2)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest.set_params(n_estimators=100,criterion=\"mse\",bootstrap=True,oob_score = False,n_jobs=-1,random_state=0,\\\n",
    "                       max_depth=grid_search_forest.best_params_['max_depth'],max_features=grid_search_forest.best_params_['max_features'],\\\n",
    "                       min_samples_leaf=2,min_samples_split=2)\n",
    "randomForest.fit(lencoded_trainX,lencoded_trainY)\n",
    "forest_best_feat=pd.Series(randomForest.feature_importances_,index=lencoded_trainX.columns)\n",
    "forest_best_feat.sort_values(ascending=False,inplace=True)\n",
    "forest_best_feat=list(forest_best_feat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive forest\n",
    "recursive_forest_score=[]\n",
    "recursive_forest_test_score=[]\n",
    "i=0\n",
    "forest_df=lencoded_trainX.copy()\n",
    "forest_df_test=lencoded_testX.copy()\n",
    "listremoval_forest=forest_best_feat.copy()\n",
    "for reduction in range(6):\n",
    "    i+=1\n",
    "    removelist=listremoval_forest[-5:-1]\n",
    "    for item in removelist:\n",
    "        listremoval_forest.remove(item)\n",
    "    forest_df.drop(removelist,axis=1,inplace=True)\n",
    "    forest_df_test.drop(removelist,axis=1,inplace=True)\n",
    "    recursive_f_para_search=GridSearchCV(ensemble.RandomForestRegressor(n_estimators=100,criterion=\"mse\",\\\n",
    "                                                                 min_samples_leaf=2,min_samples_split=2,\\\n",
    "                                                                 bootstrap=True,oob_score = True,n_jobs=-1),\\\n",
    "                                  param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1,refit=True)\n",
    "    recursive_f_para_search.fit(forest_df,trainY)\n",
    "    recursive_forest_score.append(recursive_f_para_search.score(forest_df,lencoded_trainY))\n",
    "    recursive_forest_test_score.append(recursive_f_para_search.score(forest_df_test,lencoded_testY))\n",
    "    print(i,'/',np.array(forest_best_feat).shape[0],end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.array(recursive_forest_score)*-1,c='red', label='training error')\n",
    "plt.plot(np.array(recursive_forest_test_score)*-1,c='blue', label='test error')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Features Taken Out')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Recursive forest\n",
    "# recursive_forest_score=[]\n",
    "# recursive_forest_test_score=[]\n",
    "# i=0\n",
    "# forest_df=trainX.copy()\n",
    "# forest_df_test=testX.copy()\n",
    "# for col in forest_best_feat[-1:-101:-1]:\n",
    "#     i+=1\n",
    "#     forest_df.drop(col,axis=1,inplace=True)\n",
    "#     forest_df_test.drop(col,axis=1,inplace=True)\n",
    "#     recursive_f_para_search=GridSearchCV(ensemble.RandomForestRegressor(n_estimators=100,criterion=\"mse\",\\\n",
    "#                                                                  min_samples_leaf=2,min_samples_split=2,\\\n",
    "#                                                                  bootstrap=True,oob_score = True,n_jobs=-1),\\\n",
    "#                                   param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1,refit=True)\n",
    "#     recursive_f_para_search.fit(forest_df,trainY)\n",
    "#     recursive_forest_score.append(recursive_f_para_search.score(forest_df,trainY))\n",
    "#     recursive_forest_test_score.append(recursive_f_para_search.score(forest_df_test,testY))\n",
    "#     print(i,'/',np.array(forest_best_feat[-1:-101:-1]).shape[0],end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "########################################################\n",
    "######## Predict Kaggle ################################\n",
    "# we see that mse begins rise up\n",
    "forest_df=pd.concat([lencoded_trainX.copy(),lencoded_testX.copy()],axis=0,sort=False)\n",
    "totalY=pd.concat([lencoded_trainY,lencoded_testY],axis=0,sort=False)\n",
    "\n",
    "recursive_f_para_search.fit(forest_df[forest_best_feat[:-5*3]],totalY)\n",
    "forest_predict_for_test=recursive_f_para_search.predict(forest_df[forest_best_feat[:-5*3]]) # <----- for ensemble coefficient optimization\n",
    "forest_predict=recursive_f_para_search.predict(lencoded_kaggle_test[forest_best_feat[:-5*3]])\n",
    "######## Predict Kaggle ################################\n",
    "########################################################\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Boost\n",
    "boost_param_grid = {'learning_rate': np.linspace(0.05,0.3,6), 'max_depth': range(3,8),'min_samples_split': range(2,8)}\n",
    "grid_search_boost = GridSearchCV(ensemble.GradientBoostingRegressor(n_estimators=100,max_features='sqrt',min_samples_leaf=5,random_state=0), param_grid = boost_param_grid, cv = 5, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "%time grid_search_boost.fit(lencoded_trainX, lencoded_trainY)\n",
    "# Print results    \n",
    "print('MSE Score on test data set (using best parameters): {0:.3f}'.format(-grid_search_boost.score(lencoded_testX, lencoded_testY)))\n",
    "print('RMSE in $$ on test data set (using best parameters): {0:.1f}'.format(\\\n",
    "      np.mean((np.exp(grid_search_boost.predict(lencoded_testX))-np.exp(lencoded_testY))**2)**0.5))\n",
    "\n",
    "\n",
    "gbm.set_params(n_estimators=100,learning_rate=grid_search_boost.best_params_['learning_rate'],criterion=\"mse\",random_state=0,\\\n",
    "                   max_depth=grid_search_boost.best_params_['max_depth'],min_samples_split=grid_search_boost.best_params_['min_samples_split'])\n",
    "gbm.fit(lencoded_trainX,lencoded_trainY)\n",
    "gbm_best_feat=pd.Series(gbm.feature_importances_,index=lencoded_trainX.columns)\n",
    "gbm_best_feat.sort_values(ascending=False,inplace=True)\n",
    "gbm_best_feat=list(gbm_best_feat.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive gradient boost\n",
    "recursive_gbm_score=[]\n",
    "recursive_gbm_test_score=[]\n",
    "i=0\n",
    "gbm_df=lencoded_trainX.copy()\n",
    "gbm_df_test=lencoded_testX.copy()\n",
    "listremoval_gbm=gbm_best_feat.copy()\n",
    "for reduction in range(6):\n",
    "    i+=1\n",
    "    removelist=listremoval_gbm[-5:-1]\n",
    "    for item in removelist:\n",
    "        listremoval_gbm.remove(item)\n",
    "    gbm_df.drop(removelist,axis=1,inplace=True)\n",
    "    gbm_df_test.drop(removelist,axis=1,inplace=True)\n",
    "    recursive_gbm_para_search=GridSearchCV(ensemble.GradientBoostingRegressor(n_estimators=100,max_features='sqrt',min_samples_leaf=5,random_state=0), param_grid = boost_param_grid, cv = 5, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "    recursive_gbm_para_search.fit(gbm_df,lencoded_trainY)\n",
    "    recursive_gbm_score.append(recursive_gbm_para_search.score(gbm_df,lencoded_trainY))\n",
    "    recursive_gbm_test_score.append(recursive_gbm_para_search.score(gbm_df_test,lencoded_testY))\n",
    "    print(i,'/',np.array(gbm_best_feat).shape[0],end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.array(recursive_gbm_score)*-1,c='red', label='training error')\n",
    "plt.plot(np.array(recursive_gbm_test_score)*-1,c='blue', label='test error')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Features Taken Out')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "########################################################\n",
    "######## Predict Kaggle ################################\n",
    "# we see that mse begins rise up\n",
    "gbm_df=pd.concat([lencoded_trainX.copy(),lencoded_testX.copy()],axis=0,sort=False)\n",
    "totalY=pd.concat([lencoded_trainY,lencoded_testY],axis=0,sort=False)\n",
    "\n",
    "recursive_gbm_para_search.fit(gbm_df[gbm_best_feat[:-5*2]],totalY)\n",
    "boost_predict_for_test=recursive_gbm_para_search.predict(gbm_df[gbm_best_feat[:-5*2]]) # <----- for ensemble coefficient optimization\n",
    "boost_predict=recursive_gbm_para_search.predict(lencoded_kaggle_test[gbm_best_feat[:-5*2]])\n",
    "######## Predict Kaggle ################################\n",
    "########################################################\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def test_predict_function(x):\n",
    "    \n",
    "    y=df[~df.SalePrice.isnull()].SalePrice\n",
    "    \n",
    "    return np.sum((np.array(y)-(x[0])*np.array(one_lasso_predict_for_test)-(x[1])*np.array(two_lasso_predict_for_test)-\\\n",
    "(x[2])*np.array(ols_predict_for_test)-(x[3])*np.array(ridge_predict_for_test)-(x[4])*np.array(forest_predict_for_test)-\\\n",
    "(x[5])*np.array(boost_predict_for_test))**2)\n",
    "\n",
    "coef_results=optimize.minimize(test_predict_function,[1/6,1/6,1/6,1/6,1/6,1/6], method='CG',options={'maxiter':7000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_predict=(1/6)*np.array(one_lasso_predict)+(1/6)*np.array(two_lasso_predict)+\\\n",
    "(1/6)*np.array(ols_predict)+(1/6)*np.array(ridge_predict)+(1/6)*np.array(forest_predict)+\\\n",
    "(1/6)*np.array(boost_predict)\n",
    "final_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = df_test.index\n",
    "submission['SalePrice'] = np.exp(final_predict)\n",
    "submission.to_csv('AAAG_C3_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
